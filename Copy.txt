
Here’s your Daily Learning Report for today’s theoretical learning on Scaling and Exposing Applications in Kubernetes:


---

Daily Learning Report

Date: 22nd April 2025
Name: Aman Kumar
Learning Track: DevOps – Kubernetes Fundamentals
Topic Covered: Scaling and Exposing Applications in Kubernetes


---

1. Objective of the Day

To understand how Kubernetes allows you to scale applications up/down and expose them to external traffic using different types of services.


---

2. Topics Covered

A. Scaling Applications in Kubernetes

What is Scaling?

The process of increasing or decreasing the number of Pod replicas for an application to match demand.

Kubernetes allows:

Manual scaling using kubectl scale

Auto-scaling using Horizontal Pod Autoscaler (HPA)



Why Scale?

To handle more traffic or reduce resource usage.

Helps achieve high availability and performance efficiency.


Manual Scaling Example

kubectl scale deployment my-app --replicas=4

Horizontal Pod Autoscaler (HPA)

Automatically adjusts Pod count based on CPU/memory usage or custom metrics.

Requires metrics server installed in the cluster.



---

B. Exposing Applications

Why Expose?

By default, Pods are not accessible from outside the cluster.

To make them accessible, we expose them using Kubernetes Service objects.



---

Types of Services


---

Sample Service YAML (NodePort)

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  type: NodePort
  ports:
    - port: 80
      targetPort: 8080
      nodePort: 30036


---

3. Activities Done

Theoretical study of:

Scaling deployments manually

Concepts of auto-scaling

Understanding each service type

YAML examples from Kubernetes documentation




---

4. Learnings & Takeaways

Scaling ensures app availability and performance during traffic spikes.

Kubernetes Services provide a reliable and abstracted way to expose applications.

Choosing the right service type depends on your deployment environment and security needs.



---

5. Plan for Next Day

Practice:

Manually scaling a deployment with kubectl scale

Creating a NodePort service

Observing pod/service behavior




---

Would you like a practice checklist or commands summary sheet for scaling and exposing tomorrow?

